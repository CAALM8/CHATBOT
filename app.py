import streamlit as st
from huggingface_hub import InferenceClient

st.set_page_config(page_title="Hugging Face Chatbot", layout="wide")

st.title("ğŸ˜€ Hugging Face Chatbot (Streamlit)")

# Sidebar
st.sidebar.header("è®¾ç½®")
HF_TOKEN = st.sidebar.text_input("ä½ çš„ HuggingFace Tokenï¼ˆå¿…å¡«ï¼‰", type="password")
MODEL_ID = st.sidebar.text_input("æ¨¡å‹ ID", "Qwen/Qwen2.5-7B-Instruct")

# Chat history
if "messages" not in st.session_state:
    st.session_state["messages"] = []

for msg in st.session_state["messages"]:
    with st.chat_message(msg["role"]):
        st.write(msg["content"])

user_input = st.chat_input("è¯·è¾“å…¥æ¶ˆæ¯...")

if user_input and HF_TOKEN:
    st.session_state["messages"].append({"role": "user", "content": user_input})

    with st.chat_message("assistant"):
        with st.spinner("æ­£åœ¨ç”Ÿæˆ..."):

            try:
                client = InferenceClient(
                    model=MODEL_ID,
                    token=HF_TOKEN
                )

                # --- æ ¸å¿ƒï¼šä½¿ç”¨é€šç”¨èŠå¤© API ---
                payload = {
                    "inputs": {
                        "past_user_inputs": [m["content"] for m in st.session_state["messages"] if m["role"] == "user"],
                        "generated_responses": [m["content"] for m in st.session_state["messages"] if m["role"] == "assistant"],
                        "text": user_input
                    },
                    "parameters": {
                        "temperature": 0.7,
                        "max_new_tokens": 256
                    }
                }

                response = client.post(json=payload)
                reply = response.get("generated_text", "")

                st.session_state["messages"].append({"role": "assistant", "content": reply})
                st.write(reply)

            except Exception as e:
                st.error(f"âŒ å‘ç”Ÿé”™è¯¯ï¼š{str(e)}")
