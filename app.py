import streamlit as st
from huggingface_hub import InferenceClient

st.set_page_config(page_title="Hugging Face Chatbot", layout="wide")
st.title("ğŸ˜€ Hugging Face Chatbot (Streamlit)")

# Sidebar
st.sidebar.header("è®¾ç½®")
HF_TOKEN = st.sidebar.text_input("ä½ çš„ HuggingFace Tokenï¼ˆå¿…å¡«ï¼‰", type="password")
MODEL_ID = st.sidebar.text_input("æ¨¡å‹ ID", "Qwen/Qwen2.5-7B-Instruct")

# Chat history
if "messages" not in st.session_state:
    st.session_state["messages"] = []

for msg in st.session_state["messages"]:
    with st.chat_message(msg["role"]):
        st.write(msg["content"])

user_input = st.chat_input("è¯·è¾“å…¥æ¶ˆæ¯...")

if user_input and HF_TOKEN:
    st.session_state["messages"].append({"role": "user", "content": user_input})

    with st.chat_message("assistant"):
        with st.spinner("æ­£åœ¨ç”Ÿæˆ..."):

            try:
                client = InferenceClient(
                    model=MODEL_ID,
                    token=HF_TOKEN
                )

                # æ‹¼æ¥å†å²å¯¹è¯ï¼Œæ„æˆ prompt
                history_text = ""
                for m in st.session_state["messages"]:
                    role = "User" if m["role"] == "user" else "Assistant"
                    history_text += f"{role}: {m['content']}\n"
                history_text += "Assistant:"

                # ç›´æ¥ä½¿ç”¨ text_generation â€”â€” æ‰€æœ‰ç‰ˆæœ¬éƒ½æ”¯æŒï¼
                output = client.text_generation(
                    prompt=history_text,
                    max_new_tokens=200,
                    temperature=0.7
                )

                reply = output
                st.session_state["messages"].append({"role": "assistant", "content": reply})
                st.write(reply)

            except Exception as e:
                st.error(f"âŒ å‘ç”Ÿé”™è¯¯ï¼š{str(e)}")
