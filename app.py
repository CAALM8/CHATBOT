import streamlit as st
from huggingface_hub import InferenceClient

st.set_page_config(page_title="Hugging Face Chatbot", layout="wide")

st.title("ğŸ˜€ Hugging Face Chatbot (Streamlit)")

# Sidebar
st.sidebar.header("è®¾ç½®")
HF_TOKEN = st.sidebar.text_input("ä½ çš„ HuggingFace Tokenï¼ˆå¿…å¡«ï¼‰", type="password")
MODEL_ID = st.sidebar.text_input("æ¨¡å‹ ID", "Qwen/Qwen2.5-7B-Instruct")

# Chat history
if "messages" not in st.session_state:
    st.session_state["messages"] = []

for msg in st.session_state["messages"]:
    with st.chat_message(msg["role"]):
        st.write(msg["content"])

prompt = st.chat_input("è¯·è¾“å…¥æ¶ˆæ¯...")

if prompt and HF_TOKEN:
    st.session_state["messages"].append({"role": "user", "content": prompt})

    with st.chat_message("assistant"):
        with st.spinner("æ­£åœ¨ç”Ÿæˆå›åº”..."):

            try:
                client = InferenceClient(
                    model=MODEL_ID,
                    token=HF_TOKEN
                )

                # --- ä½¿ç”¨ conversationalï¼ˆé€‚é… Qwen ç³»åˆ—ï¼‰ ---
                response = client.conversational(
                    messages=st.session_state["messages"],
                    max_new_tokens=256,
                    temperature=0.7,
                )

                reply = response["generated_text"]

                st.session_state["messages"].append({"role": "assistant", "content": reply})
                st.write(reply)

            except Exception as e:
                st.error(f"âŒ å‘ç”Ÿé”™è¯¯ï¼š{str(e)}")
