import gradio as gr
from huggingface_hub import InferenceClient

def chat_with_hf(token, model_id, user_input, history):

    if not token:
        return history + [["You", user_input], ["Bot", "âŒ è¯·å…ˆè¾“å…¥ä½ çš„ Hugging Face Token"]]

    if not model_id:
        return history + [["You", user_input], ["Bot", "âŒ è¯·å…ˆè¾“å…¥æ¨¡å‹ ID"]]

    try:
        client = InferenceClient(token=token)

        response = client.chat.completions.create(
            model=model_id,
            messages=[{"role": "user", "content": user_input}],
            max_tokens=256,
        )

        bot_reply = response.choices[0].message["content"]

        history.append(["ä½ ", user_input])
        history.append(["ğŸ¤–", bot_reply])

        return history

    except Exception as e:
        history.append(["ä½ ", user_input])
        history.append(["âŒ Error", str(e)])
        return history


with gr.Blocks() as demo:

    gr.Markdown("# ğŸ˜„ Hugging Face Chatbot")

    with gr.Row():
        token = gr.Textbox(label="ä½ çš„ HuggingFace Tokenï¼ˆå¿…å¡«ï¼‰", type="password")
        model_id = gr.Textbox(label="æ¨¡å‹ ID", placeholder="ä¾‹å¦‚ï¼šgoogle/gemma-2b-it")

    chatbot = gr.Chatbot()
    user_input = gr.Textbox(label="ä½ ï¼š")
    send_btn = gr.Button("å‘é€")
    clear_btn = gr.Button("æ¸…ç©ºå¯¹è¯")

    send_btn.click(
        chat_with_hf,
        inputs=[token, model_id, user_input, chatbot],
        outputs=[chatbot]
    )

    clear_btn.click(lambda: None, None, chatbot, queue=False)

demo.launch()
